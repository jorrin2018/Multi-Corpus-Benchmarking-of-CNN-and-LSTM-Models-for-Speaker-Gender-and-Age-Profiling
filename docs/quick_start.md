# Gu√≠a de Inicio R√°pido - Speaker Profiling

¬°Bienvenido al sistema de **Multi-Corpus Benchmarking para Speaker Profiling**! Esta gu√≠a te ayudar√° a comenzar r√°pidamente con el entrenamiento y evaluaci√≥n de modelos para clasificaci√≥n de g√©nero y edad.

## üìã √çndice

1. [Instalaci√≥n R√°pida](#instalaci√≥n-r√°pida)
2. [Configuraci√≥n Inicial](#configuraci√≥n-inicial)
3. [Primer Entrenamiento](#primer-entrenamiento)
4. [Evaluaci√≥n de Modelos](#evaluaci√≥n-de-modelos)
5. [Predicciones](#predicciones)
6. [Ejemplos Avanzados](#ejemplos-avanzados)

## üöÄ Instalaci√≥n R√°pida

### Requisitos Previos
- Python 3.8+
- CUDA (opcional, para GPU)
- Git

### Instalaci√≥n

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/speaker-profiling-benchmark.git
cd speaker-profiling-benchmark

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Instalar el paquete
pip install -e .
```

## ‚öôÔ∏è Configuraci√≥n Inicial

### 1. Estructura de Datos

Organiza tus datos siguiendo esta estructura:

```
data/
‚îú‚îÄ‚îÄ voxceleb1/
‚îÇ   ‚îú‚îÄ‚îÄ wav/
‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv
‚îÇ   ‚îî‚îÄ‚îÄ splits/
‚îú‚îÄ‚îÄ common_voice/
‚îÇ   ‚îú‚îÄ‚îÄ clips/
‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv
‚îÇ   ‚îî‚îÄ‚îÄ splits/
‚îî‚îÄ‚îÄ timit/
    ‚îú‚îÄ‚îÄ wav/
    ‚îú‚îÄ‚îÄ metadata.csv
    ‚îî‚îÄ‚îÄ splits/
```

### 2. Verificar Configuraci√≥n

```bash
# Verificar instalaci√≥n
python -c "import speaker_profiling; print('‚úÖ Instalaci√≥n exitosa')"

# Verificar configuraci√≥n
python -c "from src.utils.config_utils import ConfigManager; cm = ConfigManager(); print('‚úÖ Configuraci√≥n cargada')"
```

## üéØ Primer Entrenamiento

### Ejemplo 1: Clasificaci√≥n de G√©nero en VoxCeleb1

```bash
# Entrenar modelo CNN b√°sico
python scripts/train.py \
  --dataset voxceleb1 \
  --task gender \
  --model mobilenetv2 \
  --seed 42 \
  --epochs 10 \
  --save-model

# Ver progreso
tail -f results/voxceleb1_gender_mobilenetv2_seed42/train.log
```

**Salida esperada:**
```
================================================================================
INICIANDO ENTRENAMIENTO DE SPEAKER PROFILING
================================================================================
Dataset: voxceleb1
Tarea: gender
Modelo: mobilenetv2
Seed: 42
Pipeline: full

Usando device: cuda
GPU disponible: NVIDIA GeForce RTX 3080
Dataset cargado - Train: 85432, Val: 12204, Test: 12205
Modelo creado: mobilenetv2
N√∫mero de par√°metros: 2,223,872

Ejecutando pipeline completo de 2 etapas...
Etapa 1/2: Selecci√≥n de modelo...
Epoch 1/50: train_loss=0.4523, val_loss=0.3821, val_acc=0.8234
...
‚úÖ Entrenamiento completado
```

### Ejemplo 2: Clasificaci√≥n de Edad en Common Voice

```bash
# Entrenar modelo LSTM
python scripts/train.py \
  --dataset common_voice \
  --task age \
  --model lstm_256_2 \
  --seed 42 \
  --batch-size 64 \
  --save-model
```

### Ejemplo 3: Regresi√≥n de Edad en TIMIT

```bash
# Entrenar para regresi√≥n de edad
python scripts/train.py \
  --dataset timit \
  --task age \
  --model resnet18 \
  --seed 42 \
  --pipeline full \
  --mixed-precision \
  --save-model
```

## üìä Evaluaci√≥n de Modelos

### Evaluar Modelo Individual

```bash
# Evaluar modelo entrenado
python scripts/evaluate.py \
  --model-path results/voxceleb1_gender_mobilenetv2_seed42/final_model.pth \
  --dataset voxceleb1 \
  --task gender \
  --save-plots \
  --save-predictions
```

**Salida esperada:**
```
================================================================================
RESUMEN DE EVALUACI√ìN
================================================================================
Mejor modelo: mobilenetv2
Mejor accuracy: 0.9621

M√©tricas detalladas:
- Accuracy: 0.9621
- F1-Score: 0.9618
- Precision: 0.9625
- Recall: 0.9612
- AUC-ROC: 0.9864

‚úÖ Resultados guardados en: evaluation_results/
```

### Evaluaci√≥n Cross-Corpus

```bash
# Entrenar en VoxCeleb1 y evaluar en Common Voice
python scripts/evaluate.py \
  --model-path results/voxceleb1_gender_mobilenetv2_seed42/final_model.pth \
  --dataset common_voice \
  --task gender \
  --cross-corpus \
  --output-dir cross_corpus_results
```

### Evaluar M√∫ltiples Modelos

```bash
# Evaluar todos los modelos en un directorio
python scripts/evaluate.py \
  --models-dir results/ \
  --dataset voxceleb1 \
  --task gender \
  --save-plots
```

## üé§ Predicciones

### Predicci√≥n en Archivo Individual

```bash
# Predecir g√©nero en archivo de audio
python scripts/predict.py \
  --model-path results/voxceleb1_gender_mobilenetv2_seed42/final_model.pth \
  --audio-file sample_audio.wav \
  --task gender \
  --output-probs
```

**Salida esperada:**
```
================================================================================
RESULTADOS DE PREDICCI√ìN
================================================================================
Archivo: sample_audio.wav | G√©nero: Femenino (Confianza: 0.924)
```

### Predicci√≥n en Lotes

```bash
# Predecir en m√∫ltiples archivos
python scripts/predict.py \
  --model-path results/common_voice_age_lstm_256_2_seed42/final_model.pth \
  --audio-dir audio_samples/ \
  --task age \
  --output-file predictions.csv \
  --batch-size 32
```

### Predicci√≥n con Caracter√≠sticas Personalizadas

```bash
# Usar MFCC en lugar de mel-spectrogramas
python scripts/predict.py \
  --model-path results/timit_age_resnet18_seed42/final_model.pth \
  --audio-file audio.wav \
  --task age \
  --feature-type mfcc \
  --output-features
```

## üèÅ Ejemplos Avanzados

### 1. Benchmark Completo

```bash
# Ejecutar benchmark multi-modelo
python scripts/benchmark.py \
  --dataset voxceleb1 \
  --task gender \
  --models mobilenetv2,resnet18,lstm_256_2 \
  --seeds 42,123,456 \
  --parallel-jobs 2 \
  --save-plots
```

### 2. Reproducir Resultados del Paper

```bash
# Reproducir experimentos completos del paper
python scripts/reproduce_paper.py \
  --dataset voxceleb1 \
  --task gender \
  --statistical-analysis \
  --sota-comparison
```

### 3. Pipeline Personalizado

```python
# ejemplo_personalizado.py
from src.training.trainer import SpeakerProfilingTrainer
from src.datasets.voxceleb1 import VoxCeleb1Dataset
from src.models.cnn_models import CNNModelFactory
from src.utils.config_utils import ConfigManager

# Configuraci√≥n personalizada
config = ConfigManager().get_default_config()
config["training"]["learning_rate"] = 0.0005
config["training"]["batch_size"] = 16

# Crear dataset
dataset = VoxCeleb1Dataset(
    data_dir="data/voxceleb1",
    split="train",
    task="gender",
    cache_features=True
)

# Crear modelo
model = CNNModelFactory.create_model(
    model_name="efficientnet_b0",
    num_classes=2,
    input_shape=(1, 224, 224),
    task="gender"
)

# Entrenar
trainer = SpeakerProfilingTrainer(
    model=model,
    config=config,
    device="cuda"
)

trainer.train_full_pipeline()
```

## üìà Monitoreo y Debugging

### Ver Logs en Tiempo Real

```bash
# Seguir logs de entrenamiento
tail -f results/*/train.log

# Ver m√©tricas espec√≠ficas
grep "val_acc" results/*/train.log
```

### Verificar Estado del Sistema

```bash
# Comprobar uso de GPU
nvidia-smi

# Verificar espacio en disco
df -h

# Comprobar procesos activos
ps aux | grep python
```

### Debugging Com√∫n

1. **Error de memoria GPU:**
```bash
# Reducir batch size
python scripts/train.py --batch-size 16 ...
```

2. **Dataset no encontrado:**
```bash
# Verificar estructura de datos
ls -la data/voxceleb1/
```

3. **Modelo no converge:**
```bash
# Ajustar learning rate
python scripts/train.py --lr 0.0001 ...
```

## üìù Mejores Pr√°cticas

### 1. Nomenclatura de Experimentos
- Usa seeds consistentes para reproducibilidad
- Nombra experimentos descriptivamente
- Documenta cambios en configuraci√≥n

### 2. Gesti√≥n de Recursos
- Monitorea uso de memoria GPU
- Usa mixed precision para eficiencia
- Configura early stopping

### 3. Evaluaci√≥n
- Siempre eval√∫a en test set
- Realiza cross-corpus evaluation
- Compara con baselines establecidos

### 4. Reproducibilidad
- Fija seeds en todos los experimentos
- Documenta versiones de dependencias
- Guarda configuraciones utilizadas

## üîó Enlaces √ötiles

- [Documentaci√≥n Completa](docs/api/README.md)
- [Notebooks de Ejemplo](notebooks/)
- [Configuraci√≥n Avanzada](docs/configuration.md)
- [Soluci√≥n de Problemas](docs/troubleshooting.md)
- [Contribuir](CONTRIBUTING.md)

## üÜò Soporte

Si encuentras problemas:

1. Revisa la [documentaci√≥n](docs/)
2. Consulta [issues conocidos](https://github.com/tu-usuario/speaker-profiling-benchmark/issues)
3. Crea un [nuevo issue](https://github.com/tu-usuario/speaker-profiling-benchmark/issues/new)

---

¬°Feliz entrenamiento! üéâ Para casos de uso m√°s avanzados, consulta los [notebooks de ejemplo](notebooks/) y la [documentaci√≥n completa de la API](docs/api/). 