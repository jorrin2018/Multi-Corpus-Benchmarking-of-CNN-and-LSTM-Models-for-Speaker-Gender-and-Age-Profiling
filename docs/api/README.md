# üìö Documentaci√≥n de la API - Speaker Profiling

Documentaci√≥n completa de la API del sistema de **Multi-Corpus Benchmarking para Speaker Profiling**.

## üìã √çndice General

### üîß M√≥dulos de Preprocesamiento
- [`audio_processing`](preprocessing/audio_processing.md) - Procesamiento de se√±ales de audio
- [`feature_extraction`](preprocessing/feature_extraction.md) - Extracci√≥n de caracter√≠sticas

### üèóÔ∏è M√≥dulos de Modelos
- [`cnn_models`](models/cnn_models.md) - Factor√≠as y arquitecturas CNN
- [`lstm_models`](models/lstm_models.md) - Factor√≠as y arquitecturas LSTM

### üìä M√≥dulos de Datasets
- [`voxceleb1`](datasets/voxceleb1.md) - Dataset VoxCeleb1
- [`common_voice`](datasets/common_voice.md) - Dataset Common Voice
- [`timit`](datasets/timit.md) - Dataset TIMIT

### üéØ M√≥dulos de Entrenamiento
- [`trainer`](training/trainer.md) - Entrenador principal
- [`callbacks`](training/callbacks.md) - Sistema de callbacks

### üìà M√≥dulos de Evaluaci√≥n
- [`metrics`](evaluation/metrics.md) - Calculadora de m√©tricas
- [`benchmarking`](evaluation/benchmarking.md) - Sistema de benchmarking

### üõ†Ô∏è M√≥dulos de Utilidades
- [`config_utils`](utils/config_utils.md) - Gesti√≥n de configuraci√≥n
- [`data_utils`](utils/data_utils.md) - Utilidades de datos

---

## üöÄ Inicio R√°pido

### Importaciones B√°sicas

```python
# Configuraci√≥n
from src.utils.config_utils import ConfigManager

# Preprocesamiento
from src.preprocessing.audio_processing import AudioProcessor
from src.preprocessing.feature_extraction import FeatureExtractor

# Datasets
from src.datasets.voxceleb1 import VoxCeleb1Dataset
from src.datasets.common_voice import CommonVoiceDataset
from src.datasets.timit import TIMITDataset

# Modelos
from src.models.cnn_models import CNNModelFactory
from src.models.lstm_models import LSTMModelFactory

# Entrenamiento
from src.training.trainer import SpeakerProfilingTrainer
from src.training.callbacks import CallbackManager

# Evaluaci√≥n
from src.evaluation.metrics import MetricsCalculator
```

### Ejemplo de Uso B√°sico

```python
# Configurar sistema
config_manager = ConfigManager()
config = config_manager.get_default_config()

# Cargar dataset
dataset = VoxCeleb1Dataset(
    data_dir="data/voxceleb1",
    split="train",
    task="gender",
    cache_features=True
)

# Crear modelo
model = CNNModelFactory.create_model(
    model_name="mobilenetv2",
    num_classes=2,
    input_shape=(1, 224, 224),
    task="gender"
)

# Entrenar
trainer = SpeakerProfilingTrainer(
    model=model,
    config=config,
    device="cuda"
)

trainer.train_full_pipeline()
```

---

## üìñ Gu√≠as por M√≥dulo

### Preprocesamiento de Audio

El m√≥dulo de preprocesamiento maneja la carga, limpieza y transformaci√≥n de se√±ales de audio:

- **Eliminaci√≥n de silencios** con par√°metro q=0.075
- **Filtro pre-√©nfasis** con coeficiente 0.97
- **Filtrado Butterworth** de 10¬∫ orden, frecuencia de corte 4kHz
- **Normalizaci√≥n Z-score** para estabilidad num√©rica

```python
audio_processor = AudioProcessor(config["preprocessing"]["audio"])
processed_audio = audio_processor.preprocess_audio(raw_audio)
```

### Extracci√≥n de Caracter√≠sticas

Sistema flexible para extraer diferentes tipos de caracter√≠sticas:

- **Espectrogramas lineales** con ventana Hann
- **Mel-spectrogramas** espec√≠ficos por corpus
- **MFCC** optimizados para cada dataset

```python
feature_extractor = FeatureExtractor(config["preprocessing"]["features"])

# Mel-spectrogram para VoxCeleb1 (224x224)
mel_spec = feature_extractor.extract_mel_spectrogram(audio, dataset="voxceleb1")

# MFCC para TIMIT (13 coeficientes)
mfcc = feature_extractor.extract_mfcc(audio, dataset="timit")
```

### Factor√≠as de Modelos

Sistema de factor√≠as para crear modelos de manera consistente:

#### CNN Models

Soporta 7 arquitecturas CNN con transfer learning:

```python
# Crear modelo CNN
model = CNNModelFactory.create_model(
    model_name="efficientnet_b0",  # mobilenetv2, resnet18, etc.
    num_classes=2,
    input_shape=(1, 224, 224),
    task="gender"
)
```

#### LSTM Models

Soporta 9 configuraciones LSTM bidireccionales:

```python
# Crear modelo LSTM
model = LSTMModelFactory.create_model(
    model_name="lstm_256_2",  # 256 hidden, 2 layers
    num_classes=2,
    input_size=40,  # MFCC features
    task="gender"
)
```

### Sistema de Entrenamiento

Entrenador unificado con pipeline de 2 etapas:

```python
trainer = SpeakerProfilingTrainer(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    test_loader=test_loader,
    config=config,
    device="cuda",
    use_mixed_precision=True
)

# Pipeline completo: selecci√≥n + fine-tuning
trainer.train_full_pipeline()
```

### Sistema de Evaluaci√≥n

Calculadora de m√©tricas completa:

```python
metrics_calculator = MetricsCalculator(task="gender")

# Calcular todas las m√©tricas
metrics = metrics_calculator.calculate_metrics(targets, predictions)
# Retorna: accuracy, f1_score, precision, recall, auc_roc, etc.

# An√°lisis estad√≠stico
analysis = metrics_calculator.statistical_analysis(results_list)
# Retorna: confidence_intervals, significance_tests, etc.
```

---

## üîß Configuraci√≥n Avanzada

### Estructura de Configuraci√≥n

El sistema usa archivos YAML para configuraci√≥n:

```yaml
datasets:
  voxceleb1:
    sample_rate: 16000
    chunk_duration: 3.0
    mel_bins: 224
    
models:
  cnn:
    - mobilenetv2
    - efficientnet_b0
    - resnet18
    # ...
  
training:
  batch_size: 32
  learning_rate: 0.001
  epochs: 50
  pipeline: "full"  # selection, finetune, full
```

### Personalizaci√≥n de Modelos

#### Agregar Nuevo Modelo CNN

```python
class CustomCNN(nn.Module):
    def __init__(self, num_classes: int):
        super().__init__()
        # Implementar arquitectura personalizada
        
    def forward(self, x):
        # Implementar forward pass
        return x

# Registrar en la factor√≠a
CNNModelFactory.register_model("custom_cnn", CustomCNN)
```

#### Personalizar Pipeline de Entrenamiento

```python
# Configurar callbacks personalizados
callback_manager = CallbackManager()
callback_manager.add_callback(EarlyStoppingCallback(patience=10))
callback_manager.add_callback(LearningRateSchedulerCallback())

trainer.set_callbacks(callback_manager)
```

---

## üìä M√©tricas y Evaluaci√≥n

### M√©tricas Disponibles

#### Para Clasificaci√≥n de G√©nero
- **Accuracy**: Precisi√≥n general
- **F1-Score**: Media arm√≥nica de precision y recall
- **Precision**: Precisi√≥n por clase
- **Recall**: Sensibilidad por clase
- **AUC-ROC**: √Årea bajo la curva ROC
- **Confusion Matrix**: Matriz de confusi√≥n

#### Para Estimaci√≥n de Edad
- **MAE**: Error absoluto medio (regresi√≥n)
- **MSE**: Error cuadr√°tico medio
- **RMSE**: Ra√≠z del error cuadr√°tico medio
- **R¬≤**: Coeficiente de determinaci√≥n
- **Accuracy**: Precisi√≥n por rangos (clasificaci√≥n)

### Cross-Corpus Evaluation

Sistema para evaluar generalizaci√≥n entre datasets:

```python
# Entrenar en VoxCeleb1, evaluar en Common Voice
source_model = "results/voxceleb1_gender_mobilenetv2/model.pth"
target_dataset = CommonVoiceDataset(split="test", task="gender")

cross_metrics = evaluate_cross_corpus(source_model, target_dataset)
```

---

## üîç Debugging y Diagn√≥stico

### Logging Avanzado

```python
import logging

# Configurar logging detallado
logging.basicConfig(level=logging.DEBUG)

# Logs espec√≠ficos por m√≥dulo
logger = logging.getLogger("speaker_profiling.training")
logger.setLevel(logging.INFO)
```

### Profiling de Rendimiento

```python
# Monitorear uso de memoria GPU
torch.cuda.memory_summary()

# Profiling de tiempo de entrenamiento
with torch.profiler.profile() as prof:
    trainer.train_epoch()

print(prof.key_averages().table())
```

### Validaci√≥n de Datos

```python
# Verificar integridad del dataset
dataset.validate_integrity()

# Estad√≠sticas del dataset
stats = dataset.get_statistics()
print(f"Speakers: {stats['num_speakers']}")
print(f"Audio files: {stats['num_files']}")
```

---

## üöÄ Extensibilidad

### Agregar Nuevo Dataset

```python
class CustomDataset(BaseSpeakerDataset):
    def __init__(self, data_dir: str, split: str, task: str):
        super().__init__(data_dir, split, task)
        self.load_metadata()
    
    def load_metadata(self):
        # Implementar carga de metadatos
        pass
    
    def __getitem__(self, idx):
        # Implementar carga de muestras
        return features, label
```

### Personalizar M√©tricas

```python
class CustomMetricsCalculator(MetricsCalculator):
    def calculate_custom_metric(self, y_true, y_pred):
        # Implementar m√©trica personalizada
        return custom_score
```

---

## üìû Soporte T√©cnico

### Errores Comunes

1. **CUDA out of memory**
   ```python
   # Reducir batch_size o usar gradient_checkpointing
   config["training"]["batch_size"] = 16
   trainer.enable_gradient_checkpointing()
   ```

2. **Dataset no encontrado**
   ```python
   # Verificar estructura de directorios
   dataset.validate_data_structure()
   ```

3. **Modelo no converge**
   ```python
   # Ajustar learning rate o usar scheduler
   config["training"]["learning_rate"] = 0.0001
   trainer.use_scheduler("reduce_on_plateau")
   ```

### Contacto

Para problemas t√©cnicos o sugerencias:
- [Issues en GitHub](https://github.com/tu-usuario/speaker-profiling-benchmark/issues)
- [Documentaci√≥n completa](https://speaker-profiling-docs.readthedocs.io)
- [Ejemplos adicionales](../notebooks/)

---

**√öltima actualizaci√≥n**: 2024
**Versi√≥n de la API**: 1.0.0 